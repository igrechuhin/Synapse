---
globs: *.py
alwaysApply: false
---

# Python Performance Standards (STRICT MANDATORY - ZERO TOLERANCE)

**ENFORCEMENT**: All rules are MANDATORY. CI MUST fail on violations. NO exceptions.

## Algorithm Complexity (ENFORCED)

- **O(n) or Better**: Prefer O(n) or better algorithms - MANDATORY
- **Avoid O(n²)**: O(n²) algorithms are FORBIDDEN where O(n) is possible - MANDATORY
- **Big O Analysis**: Code review must include Big O analysis - MANDATORY

```python
# ✅ REQUIRED - O(n)
def find_duplicates(items: list[int]) -> set[int]:
    seen = set()
    duplicates = set()
    for item in items:
        if item in seen:
            duplicates.add(item)
        else:
            seen.add(item)
    return duplicates

# ❌ PROHIBITED - O(n²)
def find_duplicates_bad(items: list[int]) -> list[int]:
    duplicates = []
    for i, item1 in enumerate(items):
        for j, item2 in enumerate(items):
            if i != j and item1 == item2:
                duplicates.append(item1)
    return duplicates
```

## Data Structure Selection (ENFORCED)

- **Appropriate Structures**: Choose optimal data structures - MANDATORY
- **deque for Queues**: Use `collections.deque` for FIFO operations - MANDATORY
- **Counter for Frequency**: Use `collections.Counter` for counting - MANDATORY
- **defaultdict for Grouping**: Use `collections.defaultdict` for grouping - MANDATORY

```python
from collections import deque, Counter, defaultdict

# ✅ REQUIRED
queue = deque(items)  # O(1) append/popleft
word_counts = Counter(words)  # O(n) counting
grouped = defaultdict(list)  # No KeyError handling

# ❌ PROHIBITED
queue = list(items)  # pop(0) is O(n)
queue.pop(0)  # BLOCKED: O(n) operation
```

## List Comprehensions vs Loops (ENFORCED)

- **List Comprehensions**: Use for simple transformations - MANDATORY
- **Generator Expressions**: Use for large datasets - MANDATORY
- **itertools.batched()**: Use for chunking (Python 3.13+) - MANDATORY
- **Explicit Loops**: Use for complex logic - MANDATORY

```python
from itertools import batched

# ✅ REQUIRED
squares = [x**2 for x in numbers]
items = (process_item(item) for item in data)  # Generator
for batch in batched(items, batch_size):  # Python 3.13+
    yield [process_item(item) for item in batch]

# ❌ PROHIBITED
result = ""
for item in items:
    result += str(item)  # Creates new string each iteration
```

## String Operations (ENFORCED)

- **String Building**: Use `str.join()` for building strings - MANDATORY
- **f-strings**: Use f-strings for formatting - MANDATORY
- **NEVER Concatenate in Loops**: String concatenation in loops is FORBIDDEN - MANDATORY

```python
# ✅ REQUIRED
lines = ['<table>']
for row in rows:
    cells = [f'<td>{value}</td>' for value in row.values()]
    lines.append(f'<tr>{"".join(cells)}</tr>')
return '\n'.join(lines)

# ❌ PROHIBITED
result = '<table>'
for row in rows:
    result += '<tr>'  # Creates new string each time
```

## Database Query Optimization (ENFORCED)

- **Avoid N+1 Queries**: Use joins instead of separate queries - MANDATORY
- **Batch Operations**: Use batch updates/inserts - MANDATORY
- **Query Optimization**: Optimize queries with proper indexes - MANDATORY

```python
# ✅ REQUIRED - Single query with join
stmt = select(User.id, User.name, func.count(Post.id).label('post_count')
    ).join(Post, User.id == Post.user_id
    ).group_by(User.id, User.name)

# ❌ PROHIBITED - N+1 queries
for user in users:
    post_count = await session.execute(
        select(func.count(Post.id)).where(Post.user_id == user.id)
    )  # Separate query for each user
```

## Caching Strategies (ENFORCED)

- **Function-Level Caching**: Use `@lru_cache` for bounded caches - MANDATORY
- **Unbounded Caching**: Use `@cache` for unbounded caches (Python 3.13+) - MANDATORY
- **TTL Caching**: Implement TTL for time-sensitive data - MANDATORY

```python
from functools import lru_cache, cache

# ✅ REQUIRED
@lru_cache(maxsize=128)
def expensive_computation_bounded(n: int) -> int:
    return n * n

@cache  # Python 3.13+
def expensive_computation_unbounded(n: int) -> int:
    return n * n
```

## Async Performance (ENFORCED)

- **Concurrent Execution**: Use `asyncio.TaskGroup` for concurrent operations - MANDATORY
- **Concurrency Limits**: Use `Semaphore` to limit concurrent operations - MANDATORY
- **Batching**: Process items in batches to control memory - MANDATORY

```python
import asyncio
from asyncio import Semaphore, TaskGroup

async def fetch_multiple_urls(urls: list[str]) -> list[dict]:
    semaphore = Semaphore(10)  # Limit concurrent requests
    async def fetch_with_semaphore(url: str) -> dict:
        async with semaphore:
            return await fetch_url(url)
    async with TaskGroup() as tg:
        tasks = [tg.create_task(fetch_with_semaphore(url)) for url in urls]
    return [task.result() for task in tasks]
```

## Memory Management (ENFORCED)

- **Streaming**: Process large files line-by-line - MANDATORY
- **Generator Expressions**: Use generators for large datasets - MANDATORY
- **Batch Processing**: Process data in batches with cleanup - MANDATORY

```python
# ✅ REQUIRED
def process_large_file(file_path: Path) -> Iterator[dict]:
    with open(file_path, 'r') as file:
        for line in file:  # Process line by line
            yield process_line(line)

# ❌ PROHIBITED
with open(file_path, 'r') as file:
    content = file.read()  # Loads entire file into memory
```

## CPU-Bound Tasks (ENFORCED)

- **Process Pool**: Use `ProcessPoolExecutor` for CPU-intensive tasks - MANDATORY
- **Async Wrapper**: Use `loop.run_in_executor()` for async contexts - MANDATORY

```python
from concurrent.futures import ProcessPoolExecutor

async def async_cpu_task(data: Any) -> Any:
    loop = asyncio.get_running_loop()
    with ProcessPoolExecutor() as executor:
        return await loop.run_in_executor(executor, cpu_intensive_task, data)
```

## Profiling (ENFORCED)

- **Performance Testing**: Include performance benchmarks - MANDATORY
- **Memory Profiling**: Profile memory usage for large operations - MANDATORY
- **CI Benchmarks**: Include performance regression tests in CI - MANDATORY

## Violations (BLOCKED)

- ❌ O(n²) or worse algorithms where O(n) possible
- ❌ Loading entire files into memory unnecessarily
- ❌ Inefficient data structure usage (list.pop(0), dict lookups in loops)
- ❌ String concatenation in loops
- ❌ N+1 database query patterns
- ❌ Unbounded async concurrency
- ❌ Blocking CPU-bound work on async event loop
- ❌ Missing performance profiling and benchmarking
- ❌ Inefficient memory usage patterns
- ❌ No caching for expensive operations

## Enforcement

- **Performance Benchmarks**: CI must include performance regression tests
- **Memory Profiling**: Automated memory usage monitoring
- **Algorithm Analysis**: Code review must include Big O analysis
- **Caching Requirements**: Performance-critical paths must include caching
- **NO exceptions**: All performance violations must be fixed before merge
